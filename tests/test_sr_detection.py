#!/usr/bin/env python3
"""
Test script per verificare le modifiche al sistema S/R
"""
import numpy as np
import sys
import os

# Aggiungi il path del progetto correttamente
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
src_dir = os.path.join(project_root, 'src')

# Aggiungi i path necessari
sys.path.insert(0, project_root)
sys.path.insert(0, src_dir)

def test_sr_target_generation():
    """Test delle modifiche per evitare target degeneration"""
    print('ðŸ§ª Testing S/R target generation fixes...')
    
    # Simula dati di test realistici
    np.random.seed(42)  # Per risultati riproducibili
    
    test_data = {
        'prices': np.random.normal(21400, 50, 1000),
        'volumes': np.random.exponential(1000, 1000),
        'timestamps': np.arange(1000)
    }
    
    def simulate_improved_sr_detection(data):
        """Simula la logica S/R migliorata"""
        prices = data['prices']
        volumes = data['volumes']
        
        X, y = [], []
        for i in range(150, 900):  # Simula il loop principale
            current_price = prices[i]
            historical_prices = prices[i-100:i]
            
            # ðŸ”§ FIX 1: Parametri piÃ¹ permissivi
            swing_window = 10  # Aumentato da 5
            volume_threshold = np.percentile(volumes[i-100:i], 40)  # Diminuito da 60
            
            # ðŸ”§ FIX 2: Strategia multipla per S/R detection
            resistance_candidates = []
            support_candidates = []
            
            # Strategia 1: Swing Highs/Lows
            for j in range(swing_window, len(historical_prices) - swing_window):
                price_j = historical_prices[j]
                volume_j = volumes[i-100+j]
                
                # Swing high con volume significativo
                is_swing_high = (price_j > np.max(historical_prices[j-swing_window:j]) and 
                                price_j > np.max(historical_prices[j+1:j+swing_window+1]) and
                                volume_j > volume_threshold)
                
                # Swing low con volume significativo
                is_swing_low = (price_j < np.min(historical_prices[j-swing_window:j]) and 
                               price_j < np.min(historical_prices[j+1:j+swing_window+1]) and
                               volume_j > volume_threshold)
                
                if is_swing_high:
                    resistance_candidates.append(price_j)
                if is_swing_low:
                    support_candidates.append(price_j)
            
            # Strategia 2: Percentili se pochi candidati
            if len(resistance_candidates) < 2:
                resistance_candidates.extend([
                    np.percentile(historical_prices, 85),
                    np.percentile(historical_prices, 90),
                    np.percentile(historical_prices, 95)
                ])
            
            if len(support_candidates) < 2:
                support_candidates.extend([
                    np.percentile(historical_prices, 15),
                    np.percentile(historical_prices, 10),
                    np.percentile(historical_prices, 5)
                ])
            
            # Strategia 3: Livelli psicologici
            price_range = np.max(historical_prices) - np.min(historical_prices)
            if price_range > 0:
                for multiplier in [0.2, 0.5, 0.8]:
                    level = np.min(historical_prices) + price_range * multiplier
                    if level > current_price:
                        resistance_candidates.append(level)
                    elif level < current_price:
                        support_candidates.append(level)
            
            # ðŸ”§ FIX 3: Fallback con randomness
            atr = np.std(historical_prices[-20:]) * 2
            random_factor = np.random.uniform(0.8, 1.2)
            
            if len(resistance_candidates) == 0:
                resistance = current_price + atr * np.random.uniform(1.2, 1.8) * random_factor
            else:
                valid_resistances = [r for r in resistance_candidates if r > current_price]
                if valid_resistances:
                    resistance = min(valid_resistances)
                else:
                    resistance = current_price + atr * np.random.uniform(1.5, 2.5) * random_factor
            
            if len(support_candidates) == 0:
                support = current_price - atr * np.random.uniform(1.2, 1.8) * random_factor
            else:
                valid_supports = [s for s in support_candidates if s < current_price]
                if valid_supports:
                    support = max(valid_supports)
                else:
                    support = current_price - atr * np.random.uniform(1.5, 2.5) * random_factor
            
            # ðŸ”§ FIX 4: Target con verifica precoce qualitÃ 
            support_distance = abs(support - current_price) / current_price
            resistance_distance = abs(resistance - current_price) / current_price
            
            # Verifica precoce qualitÃ  - aggiungi variabilitÃ  se necessario
            if support_distance < 0.0005 or resistance_distance < 0.0005:
                support_distance = max(support_distance, np.random.uniform(0.001, 0.005))
                resistance_distance = max(resistance_distance, np.random.uniform(0.001, 0.005))
            
            X.append(historical_prices[-50:])  # Features
            y.append([support_distance, resistance_distance])  # Target
        
        return np.array(X), np.array(y)
    
    # Esegui test
    X, y = simulate_improved_sr_detection(test_data)
    _ = X  # Use X to suppress warning
    
    # Analizza risultati
    support_targets = y[:, 0]
    resistance_targets = y[:, 1]
    
    print(f'ðŸ“Š Test Results:')
    print(f'   Total samples: {len(y)}')
    print(f'   Support targets - mean: {np.mean(support_targets):.6f}, std: {np.std(support_targets):.6f}')
    print(f'   Support targets - min: {np.min(support_targets):.6f}, max: {np.max(support_targets):.6f}')
    print(f'   Support unique values: {len(np.unique(support_targets))}')
    print(f'   Resistance targets - mean: {np.mean(resistance_targets):.6f}, std: {np.std(resistance_targets):.6f}')
    print(f'   Resistance targets - min: {np.min(resistance_targets):.6f}, max: {np.max(resistance_targets):.6f}')
    print(f'   Resistance unique values: {len(np.unique(resistance_targets))}')
    
    # Verifica degenerazione
    support_std = np.std(support_targets)
    resistance_std = np.std(resistance_targets)
    support_unique = len(np.unique(support_targets))
    resistance_unique = len(np.unique(resistance_targets))
    
    is_degenerate = (support_std < 1e-6 and resistance_std < 1e-6) or (support_unique < 5 and resistance_unique < 5)
    
    print(f'\nðŸ” Target Degeneration Analysis:')
    print(f'   Support std: {support_std:.8f} (threshold: 1e-6)')
    print(f'   Resistance std: {resistance_std:.8f} (threshold: 1e-6)')
    print(f'   Support unique: {support_unique} (threshold: 5)')
    print(f'   Resistance unique: {resistance_unique} (threshold: 5)')
    print(f'   Is degenerate: {is_degenerate}')
    
    if not is_degenerate:
        print('âœ… SUCCESS: Target degeneration FIXED!')
        print('âœ… The improved algorithm generates diverse, non-degenerate targets')
    else:
        print('âŒ FAILURE: Target degeneration still present')
        print('âŒ Need further improvements to the algorithm')
    
    # Test delle condizioni limite
    print(f'\nðŸ§ª Edge Case Testing:')
    
    # Test con dati molto stabili (bassa volatilitÃ )
    stable_data = {
        'prices': np.random.normal(21400, 1, 1000),  # VolatilitÃ  molto bassa
        'volumes': np.random.exponential(1000, 1000),
        'timestamps': np.arange(1000)
    }
    
    X_stable, y_stable = simulate_improved_sr_detection(stable_data)
    _ = X_stable  # Use X_stable to suppress warning
    support_stable = y_stable[:, 0]
    resistance_stable = y_stable[:, 1]
    
    stable_std = min(np.std(support_stable), np.std(resistance_stable))
    stable_unique = min(len(np.unique(support_stable)), len(np.unique(resistance_stable)))
    
    print(f'   Low volatility test - min std: {stable_std:.8f}, min unique: {stable_unique}')
    
    if stable_std > 1e-6 and stable_unique >= 5:
        print('âœ… PASS: Low volatility edge case handled correctly')
    else:
        print('âŒ FAIL: Low volatility still causes degeneration')
    
    return not is_degenerate

def test_actual_analyzer():
    """Test the actual Analyzer implementation with REAL DATA"""
    print('\nðŸ” Testing actual Analyzer implementation with REAL DATA...')
    
    try:
        # Import con percorso completo per risolvere i problemi dell'IDE
        from src.Analyzer import AssetAnalyzer as Analyzer
        from src.Unified_Analyzer_System import UnifiedConfig, SystemMode, PerformanceProfile
        import os
        import json
        
        # Create test config
        config = UnifiedConfig.for_backtesting("USTEC")
        config.system_mode = SystemMode.TESTING
        config.performance_profile = PerformanceProfile.NORMAL
        config.learning_phase_enabled = True
        config.min_learning_days = 1
        config.max_tick_buffer_size = 1000
        
        # Initialize analyzer
        analyzer = Analyzer("USTEC", "./test_analyzer_data")
        
        # Carica dati reali dal file di backtesting
        data_file = "./test_analyzer_data/backtest_USTEC_20250516_20250715.jsonl"
        if not os.path.exists(data_file):
            raise FileNotFoundError(f"âŒ Real backtest data file not found: {data_file}")
        
        print(f"ðŸ“Š Loading REAL data from: {data_file}")
        
        # Leggi i dati reali - struttura completa (limitato per test performance)
        real_data = []
        tick_count = 0
        max_ticks = 10000  # Limita per test performance
        
        with open(data_file, 'r') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    real_data.append(data)
                    if data.get('type') == 'tick':
                        tick_count += 1
                        if tick_count >= max_ticks:
                            break
                except:
                    continue
        
        print(f"ðŸ“Š Loaded {len(real_data)} real data entries")
        
        if len(real_data) < 100:
            raise ValueError(f"âŒ Not enough real data ({len(real_data)} samples). Need at least 100 samples for valid test.")
        
        # Estrai prezzi e volumi dai dati reali
        prices = []
        volumes = []
        
        for entry in real_data:
            try:
                # Filtra solo i tick (ignora metadati)
                if entry.get('type') == 'tick':
                    # Struttura: {"type": "tick", "bid": 21389.2, "ask": 21390.15, "volume": 0, ...}
                    bid = entry.get('bid')
                    ask = entry.get('ask')
                    volume = entry.get('volume', 1)
                    
                    if bid is not None and ask is not None and bid > 0 and ask > 0:
                        price = (bid + ask) / 2  # Mid price
                        prices.append(float(price))
                        volumes.append(float(max(volume, 1)))  # Evita volume 0
                    
            except Exception as e:
                continue
        
        if len(prices) < 100:
            raise ValueError(f"âŒ Not enough valid price data ({len(prices)} samples). Need at least 100 samples for valid test.")
        
        # Converti in numpy arrays
        prices = np.array(prices)
        volumes = np.array(volumes)
        
        # Calcola indicatori tecnici dai dati reali
        sma_20 = np.convolve(prices, np.ones(20)/20, mode='same')
        
        # RSI sui dati reali
        price_changes = np.diff(prices, prepend=prices[0])
        gains = np.where(price_changes > 0, price_changes, 0)
        losses = np.where(price_changes < 0, -price_changes, 0)
        avg_gains = np.convolve(gains, np.ones(14)/14, mode='same')
        avg_losses = np.convolve(losses, np.ones(14)/14, mode='same')
        rs = avg_gains / (avg_losses + 1e-10)
        rsi = 100 - (100 / (1 + rs))
        
        test_data = {
            'prices': prices,
            'volumes': volumes,
            'sma_20': sma_20,
            'rsi': rsi
        }
        
        print(f'ðŸ“Š Loaded REAL data:')
        print(f'   Samples: {len(prices)}')
        print(f'   Price range: {np.min(prices):.2f} - {np.max(prices):.2f}')
        print(f'   Price volatility: {np.std(prices):.2f}')
        print(f'   Volume range: {np.min(volumes):.2f} - {np.max(volumes):.2f}')
        
        # Test the actual method through RollingWindowTrainer
        print('\nðŸ”§ Testing actual _prepare_sr_dataset...')
        # Access the method through the analyzer's rolling_trainer
        if hasattr(analyzer, 'rolling_trainer'):
            prepare_method = getattr(analyzer.rolling_trainer, '_prepare_sr_dataset', None)
            if prepare_method:
                print(f'âœ… Method _prepare_sr_dataset found in rolling_trainer')
                X, y = prepare_method(test_data)
            else:
                print('âŒ Method _prepare_sr_dataset not found in rolling_trainer')
                print(f'Available methods: {[m for m in dir(analyzer.rolling_trainer) if m.startswith("_prepare")]}')
                return False
        else:
            print('âŒ rolling_trainer not found in analyzer')
            return False
        
        print(f'âœ… Method executed successfully')
        print(f'   X shape: {X.shape}')
        print(f'   y shape: {y.shape}')
        
        if len(y) > 0:
            print(f'\nðŸ“Š Real Implementation S/R Analysis (REAL DATA):')
            
            support_targets = y[:, 0]
            resistance_targets = y[:, 1]
            
            print(f'   Support: mean={np.mean(support_targets):.8f}, std={np.std(support_targets):.8f}')
            print(f'            min={np.min(support_targets):.8f}, max={np.max(support_targets):.8f}')
            print(f'            unique={len(np.unique(support_targets))}')
            
            print(f'   Resistance: mean={np.mean(resistance_targets):.8f}, std={np.std(resistance_targets):.8f}')
            print(f'               min={np.min(resistance_targets):.8f}, max={np.max(resistance_targets):.8f}')
            print(f'               unique={len(np.unique(resistance_targets))}')
            
            # Check degeneration
            all_zeros = np.all(y == 0)
            support_std = np.std(support_targets)
            resistance_std = np.std(resistance_targets)
            support_unique = len(np.unique(support_targets))
            resistance_unique = len(np.unique(resistance_targets))
            
            print(f'\nðŸš¨ Degeneration Check:')
            print(f'   All zeros: {all_zeros}')
            print(f'   Support std: {support_std:.8f} (threshold: 1e-6)')
            print(f'   Resistance std: {resistance_std:.8f} (threshold: 1e-6)')
            print(f'   Support unique: {support_unique} (threshold: 5)')
            print(f'   Resistance unique: {resistance_unique} (threshold: 5)')
            
            # More comprehensive degeneration check
            is_degenerate = (all_zeros or 
                           (support_std < 1e-6 and resistance_std < 1e-6) or
                           (support_unique < 5 and resistance_unique < 5))
            
            if is_degenerate:
                print('âŒ FAIL: Real implementation shows degeneration with REAL DATA!')
                if all_zeros:
                    print('   Reason: All targets are zero')
                elif support_std < 1e-6 and resistance_std < 1e-6:
                    print('   Reason: Very low variance in both support and resistance')
                else:
                    print('   Reason: Too few unique values in targets')
                return False
            else:
                print('âœ… SUCCESS: Real implementation generates valid S/R targets from REAL DATA')
                return True
        else:
            print('âŒ No samples generated by real implementation')
            return False
            
    except Exception as e:
        print(f'âŒ Error testing actual analyzer: {str(e)}')
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    print('ðŸ§ª S/R Target Generation Test Suite')
    print('='*50)
    
    # Test simulated version
    success_sim = test_sr_target_generation()
    
    # Test actual implementation
    success_real = test_actual_analyzer()
    
    print('\n' + '='*50)
    print('ðŸ Test Results:')
    print(f'   Simulated algorithm: {"âœ… PASS" if success_sim else "âŒ FAIL"}')
    print(f'   Real implementation: {"âœ… PASS" if success_real else "âŒ FAIL"}')
    
    if success_sim and not success_real:
        print('\nðŸ” DIAGNOSIS: Simulated algorithm works but real implementation fails!')
        print('   This suggests a bug in the actual Analyzer._prepare_sr_dataset method.')
        print('   The logic is correct but there might be an edge case or data issue.')
    
    sys.exit(0 if (success_sim and success_real) else 1)